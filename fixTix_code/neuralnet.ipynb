{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anand/anaconda2/envs/tensorflow/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating Features\n",
    "with open('delhiToPNBE.csv') as file:\n",
    "    data = file.readlines()\n",
    "size =len(data)-1\n",
    "label = np.ones(size)\n",
    "features = np.zeros((size,12))\n",
    "j=0\n",
    "for line in data[1:]:\n",
    "    line=line.strip()\n",
    "    line = line.split(\",\")\n",
    "    label[j]=line[0]\n",
    "    features[j]=line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10],line[11],line[12],line[13],line[14]\n",
    "    #print (features[j])\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(size):\n",
    "    if label[i]==-1:\n",
    "        label[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_label = []\n",
    "for i in label:\n",
    "    new_label.append([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train , x_test,  y_train, y_test = train_test_split(features,label,test_size = 0.2) #Split for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession() #TF Interactive Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError(\"Nesting violated for default stack of <type 'weakref'> objects\",) in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f90617bb250>> ignored\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# a batch of inputs of 2 value each\n",
    "inputs = tf.placeholder(tf.float32, shape=[None, 12])\n",
    "\n",
    "# a batch of output of 1 value each\n",
    "desired_outputs = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "# two Hidden layers\n",
    "# define the number of hidden units in the first layer\n",
    "HIDDEN_UNITS =  25 #20\n",
    "\n",
    "# connect 12 inputs to s\n",
    "# Initialize weights with random numbers, to make the network learn\n",
    "weights_1 = tf.Variable(tf.truncated_normal([12, HIDDEN_UNITS]))\n",
    "\n",
    "# The biases are single values per hidden unit\n",
    "biases_1 = tf.Variable(tf.zeros([HIDDEN_UNITS]))\n",
    "\n",
    "# connect 2 inputs to every hidden unit. Add bias\n",
    "layer_1_outputs = tf.nn.tanh(tf.matmul(inputs, weights_1) + biases_1)\n",
    "\n",
    "\n",
    "# connect first hidden units to 2 hidden units in the second hidden layer\n",
    "weights_2 = tf.Variable(tf.truncated_normal([HIDDEN_UNITS, 5]))\n",
    "# [!] The same of above\n",
    "biases_2 = tf.Variable(tf.zeros([5]))\n",
    "\n",
    "# connect the hidden units to the second hidden layer\n",
    "layer_2_outputs = tf.nn.tanh(\n",
    "    tf.matmul(layer_1_outputs, weights_2) + biases_2)\n",
    "\n",
    "# create the new layer\n",
    "weights_3 = tf.Variable(tf.truncated_normal([5, 1]))\n",
    "biases_3 = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "logits = tf.nn.tanh(tf.matmul(layer_2_outputs, weights_3) + biases_3)\n",
    "\n",
    "##\n",
    "cost_OP =  0.5 * tf.reduce_sum(tf.sub(logits, desired_outputs) * tf.sub(logits, desired_outputs))\n",
    "\n",
    "\n",
    "# OPTIMIZATION ALGORITHM i.e. GRADIENT DESCENT\n",
    "training_OP = tf.train.GradientDescentOptimizer(0.001).minimize(cost_OP)  \n",
    "\n",
    "sess.run(tf.initialize_all_variables()) #Sess run Variables\n",
    "\n",
    "training_inputs = features #T_P\n",
    "\n",
    "training_outputs = label #T_O\n",
    "\n",
    "loss_f=[]\n",
    "iterations =1000 \n",
    "acc=[]\n",
    "\n",
    "for i in range(iterations):\n",
    "    x_train , x_test,  y_train, y_test = train_test_split(features,new_label,test_size = 0.2)\n",
    "    _, loss = sess.run([training_OP, cost_OP],  #Session Run to calculate \n",
    "                       feed_dict={inputs: np.array(x_train), ## Feed Dict to feed in the neural net\n",
    "                                  desired_outputs: np.array(y_train)})\n",
    "    \n",
    "    loss_f.append([loss])\n",
    "    predicted_outputs = sess.run([logits],feed_dict={inputs: np.array(x_test),\n",
    "                                  desired_outputs: np.array(y_test)}) ## Predicited Outputs from net\n",
    "    count = 0\n",
    "    for j in range(len(y_test)):\n",
    "        if abs(predicted_outputs[0][j]-y_test[j])<=0.5:\n",
    "            count+=1\n",
    "    accuracy = count/len(y_test)\n",
    "    acc.append([accuracy])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_outputs=np.array(predicted_outputs)\n",
    "predicted_outputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "t = np.linspace(1, iterations, iterations)\n",
    "plt.plot(t, np.array(acc))\n",
    "plt.xlabel('iterations', fontsize=18)\n",
    "plt.ylabel('accuracy', fontsize=16)\n",
    "plt.title(\"Accuracy for delhi_pune_neural_net\")\n",
    "fig.savefig('accuracy_Delhi_pune.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
